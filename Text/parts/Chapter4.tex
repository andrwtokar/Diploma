\section{Исследование моделей}
\label{sec:Chapter4} \index{Chapter4}

В данной главе я опишу поставленный эксперимент по исследованию моделей и приведу полученные результаты.

\subsection{Описание эксперимента}

Эксперимент, как и вся работа разделен на две части: исследование моделей распознавания ключевых точек на теле человека и исследование моделей классификации поз человека.

В работе были выбраны несколько моделей распознавания ключевых точек на теле человека и проведен их анализ. Для выбора использовались некоторые критерии:

\begin{itemize}
	\item Доступность модели для исследований\\
	Необходимо оценить длительность установки и возможности работы с различными операционными системами. Эксперимент проводился на платформе Google Colab, поэтому необходимо было рассмотреть возможность использования модели на в Colaboratory.
	\item Новизна модели\\
	Представленная выборка была создана в основном в 2010-х, но модель DeepPose является самой старой. Новые разработки опирались на результаты, полученные в ней, и таким образом получали более хорошие результаты.
	\item Наличие документации\\
	Все модели производят классификацию по двум осям изображения: высота и ширина, а также по параметру видимость ключевой точки. Некоторые модели выдают данные нормированные на размер изображения (число из отрезка [0,1]), а некоторые точное значение в пикселях. Поэтому для работы необходимо было понимать как работает API модели, какие у нее входные - выходные данные.
	\item Тренировка модели на датасете COCO\\
	Все используемые претренированные модели были обучены на наборе данных COCO \cite{COCO_topology} в совместительстве с каким-либо другим датасетом. В некоторых  примерах не было возможности использовать претренированную модель и из-за этого они были отсеяны.
\end{itemize}

В итоге было выбрано 4 модели наиболее подходящие под критерии:
\begin{enumerate}
	\item BlazePose
	\item MoveNet.SinglePose
	\item OpenPose
	\item MMpose
\end{enumerate}

Для проведения качественного анализа и выявления лучшей модели необходимо их сравнить. Поэтому рассмотрим метрики, которые подходят для задач в 2-х мерном пространстве:

\begin{itemize}
	\item Percentage of Detection Joints\\
	PDJ оценивает точность распознавания ключевой точки в зависимости от диагональных размеров человека. При рассмотрении задачи распознавания человека мы получаем координаты точек, которые характеризуют прямоугольник, внутри которого вписан человек. Диагональ этого прямоугольника используется при высчитывании метрики PDJ (см. \autoref{fig:PDJ}). Формулу можно представить в следующем виде:
	\begin{equation}
		PDJ = \frac{\sum_{i=1}^{n} bool(d_i < threshold * diag)}{n},
	\end{equation}
	
	где\\
	$d_i$ - расстояние между предсказанной и правильной точкой,\\
	$threshold$ - порог, задаваемый исследователем,\\
	$diag$ - размер диагонали прямоугольника, внутри которого находится человек,\\
	$bool()$ - логическое условие, возвращает 1, если оно верно и 0 в ином случае,\\
	$n$ - размер выборки.
	
	С помощью значения порога можно варьировать допустимую погрешность расстояния между истинной и предсказанной точками.
	\begin{figure}[h]
		\centering
		\includegraphics[width=\textwidth * 4 / 5]{./images/PDJ}
		\caption{Визуальное представление метрики PDJ.\\ \href{hhttps://miro.medium.com/max/1400/1*dJhVudwq7pb_xl3yPEH37Q.jpeg}{Оригинальное изображение}}
		\label{fig:PDJ}
	\end{figure}

	\item Percentage of Correct Key-points\\
	PCK очень похожа на предыдущую метрику, только погрешность рассматривается относительно высоты человека. Формулу можно представить в следующем виде:
	\begin{equation}
		PDJ = \frac{\sum_{i=1}^{n} bool(d_i < threshold * body_height)}{n},
	\end{equation}
	
	где\\
	$d_i$ - расстояние между предсказанной и правильной точкой,\\
	$threshold$ - порог, задаваемый исследователем,\\
	$body_height$ - высота прямоугольника, внутри которого находится человек,\\
	$bool()$ - логическое условие, возвращает 1, если оно верно и 0 в ином случае,\\
	$n$ - размер выборки.
	
	В представленных выше двух метриках необходимо знать размеры прямоугольника, ограничивающего человека. Для этого необходимо использовать модель распознавания объектов, которая будет давать нам эти данные. При работе с метрикой PCK можно обойтись без такой модели, потому что во всех топологиях есть точки, которые обозначают верхнюю и нижнюю границы человека. Отсюда погрешность вычисления через модель и вычисления разности ординат верхней и нижней точек будет мала. Что требует меньше затрат для оценки.
	
	\item Object Key-point Similarity\\
	OKS является основной при оценке задачи Keypoint Detection COCO \cite{COCO_topology}. Она использует третью координату выходного предсказания и расстояние между реальной и предсказанной точками. Формулу можно представить в следующем виде:
	\begin{equation}
		OKS = \frac{\sum_{i} exp\left( - d_i^2 / 2s^2k_i^2\right)\delta\left(v_i > 0\right)}{\sum_{i} \delta\left(v_i > 0\right)},
	\end{equation}
	где\\
	$d_i$ - расстояние между предсказанной и правильной точкой,\\
	$s$ - площадь объекта,\\
	$k_i$ - константа ключевой точки, контролирующаю спад,\\
	$v_i$ - видимость.
	
	При оценке задачи детекции ключевых точек COCO вводится метрика Average Precision (AP) через OKS. Изменяя границу допустимого значения OKS можно получать различные значения precision и AP.
\end{itemize}

\subsection{Поиск данных}

Первым делом необходимо было проверить модели на неразмеченных данных. Для этого были выбраны фотографии высокого разрешения, где человек изображен во весь рост (см. \autoref{fig:test_photos}).

\begin{figure}[h]
\begin{subfigure}[b]{.5\textwidth}
	\centering
	\includegraphics[width=\textwidth]{./images/Test/ролики2}
	\caption{ }
\end{subfigure}
\begin{subfigure}[b]{.5\textwidth}
	\centering
   \includegraphics[width=\textwidth]{./images/Test/скамека3}
   \caption{ }
\end{subfigure}
\begin{subfigure}[b]{.5\textwidth}
	\centering
   \includegraphics[height=\textwidth]{./images/Test/dress}
   \caption{ }
\end{subfigure}
\begin{subfigure}[b]{.5\textwidth}
	\centering
   \includegraphics[height=\textwidth]{./images/Test/static}
   \caption{ }
\end{subfigure}
   \caption{Изображения для визуальной оценки моделей.}
   \label{fig:test_photos}
\end{figure}

Для качественной оценки работы моделей с помощью метрик необходимо было найти размеченные данные. Приведу описание датасетов, которые были мной рассмотрены:

\begin{itemize}
	\item COCO Dataset и MPII\\
	Данные наборы являются основными при работе с компьютерным зрением и большинство исследователей используют их как тренировочные для своих моделей. Поэтому использовать их в качестве тестовых не целесообразно. \cite{COCO_dataset, MPII_dataset}
	\item HUMAN 3.6M\\
	Данные собирались специально для задачи классификации движений человека в студии. С помощью датчиков фиксировались положения всех суставов и ключевых точек. Это идеальный датасет, но доступ к нему ограничен и создатель не выходит на связь. \cite{h36m_pami}
	\item LSP\\
	Данные собраны со спортивных соревнований и пред обработаны до обозначения одного человека на изображении размером не менее 150 пикселей в высоту. Единственная проблема - не описаны точки на лице, поэтому оценивать можно только распознавание суставов или, другими словами, точек на теле человека. \cite{LSP}
	\item LSP Extended\\
	Является расширенной версией предыдущего набора данных. По объёму превосходит его в пять раз. Остальные характеристики не поменялись. \cite{LSPE}
	\item Halpe\\
	Датасет для распознавания точек на всем теле человека. К каждой фотографии идет аннотация из 136 точек, краев ограничивающего прямоугольника и категории детектируемого объекта (во всех фотографиях стоит категория человек).
	
	Набор состоит из двух частей: HICO-DET и COCO. Все они аннотированны описанные выше способом. Для наших моделей необходимо будет отобрать только 17 точек, совпадающих с топологией СОСО. \cite{Halpe_dataset}
\end{itemize}

Выше были представлены наборы данных для задачи распознавания точек на теле человека. Но основной темой является классификация движений человека. Поэтому необходимы фотографии с меткой класса для позы, представленной на данных. Некоторые из уже представленных (COCO, MPII) тоже могут использоваться для классификации позы, но по тем же причинам, что и описаны выше, они не будут рассмотрены в эксперименте. Приведу описание датасетов для классификации движения человека по позе на изображении:


\begin{itemize}
	\item Stanford-40\\
	Набор данных состоит примерно из 10 тыс. изображений, на каждом из которых человек делает одно из 40 действий. На один класс приходится от 180 до 300 фотографий. \cite{stanford40}
	\item Yoga-82\\
	Сложность распознавания поз йоги в том, что многие из них не могут быть точно аннотированы. Для решения этой проблемы и был собран этот набор данных вмещающий примерно 28 тыс. изображений. 82 различные позы разделены по 6 подклассам. При желании можно использовать метки и классов, и подклассов для классификации. \cite{verma2020yoga}
\end{itemize}

Итого были выбраны наборы данных LSP, LSPE и Halpe. \begin{figure}[h]
\begin{subfigure}[b]{.2\textwidth}
	\centering
	\includegraphics[height=\textwidth]{./images/LSP1}
\end{subfigure}
\begin{subfigure}[b]{.1\textwidth}
	\centering
   \includegraphics[height=2\textwidth]{./images/LSP2}
\end{subfigure}
\begin{subfigure}[b]{.2\textwidth}
	\centering
   \includegraphics[height=\textwidth]{./images/LSP3}
\end{subfigure}
\begin{subfigure}[b]{.15\textwidth}
	\centering
   \includegraphics[height=4\textwidth / 3]{./images/LSP4}
\end{subfigure}
\begin{subfigure}[b]{.15\textwidth}
	\centering
   \includegraphics[height=4\textwidth / 3]{./images/LSP5}
\end{subfigure}
\begin{subfigure}[b]{.15\textwidth}
	\centering
   \includegraphics[height=4\textwidth / 3]{./images/LSP6}
\end{subfigure}
   \caption{Примеры изображений из датасета LSP.}
   \label{fig:test_photos}
\end{figure}

\subsection{Результаты эксперимента}

Рассмотрим результаты первой части работы.

Для каждой модели была рассмотрена локализация ключевых точек на фотографиях высокого качества (см. \autoref{fig:test_photos}), а также набор данных низкого качества с обработанными изображениями.

Метрики были рассчитаны с порогами 0.05, 0.2, 0.5. В дополнение к этому был проведен временной анализ классификации одного изображения в среднем по целому датасету.

Перейдем к результатам по каждой модели.
\hfill \break

\textbf{
	\begin{large}
		BlazePose
	\end{large}
}

Результаты работы модели можно посмотреть на \autoref{fig:MP_result}. Как можно заметить, некоторые точки не распознаются и не отображаются на итоговом результате. А также есть небольшая погрешность при распознавании глаз. Но модель хорошо сработала на человека в маске.

Исходя из значений метрик (см. в \autoref{tab:MP_table}) можно сделать вывод, что модель имеет высокую погрешность при среднем времени обработки одной фотографии 0.063 секунды.

\begin{table}[h]
	\centering
	\begin{tabular}{|p{1.5cm}||p{2.2cm}|p{2cm}|p{2cm}|p{2.2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&PCK@0.05&PCK@0.2&PCK@0.5&PDJ@0.05&PDJ@0.2&PDJ@0.5\\\hline
		\hline
		LSP & 0.035 & 0.304 & 0.741 & 0.042 & 0.359 & 0.815\\
		LSPE & 0.005 & 0.059 & 0.277 & 0.009 & 0.108 & 0.457\\
		\hline
	\end{tabular}
	\begin{tabular}{|p{1.5cm}||p{2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&AP@0.5&AP@0.75&AP\\\hline\hline
		LSP & 0.012 & 0.004 & 0.006\\
		LSPЕ & 0.03 & 0.001 & 0.001\\
		\hline
	\end{tabular}
	\caption{Результаты вычисления метрик для BlazePose.}
	\label{tab:MP_table}
\end{table}
\hfill \break

\textbf{
	\begin{large}
		MoveNet.SinglePose
	\end{large}
}

Результаты работы модели можно посмотреть на \autoref{fig:MN_result}. Заметны огрехи в распознавании локтей и ладоней. Как и в прошлой модели есть неточности при распознавании частей лица.

Исходя из значений метрик (см. в \autoref{tab:MN_table}) можно сделать вывод, что модель показала себя плохо при оценивании с порогом 0.05, но лучший результат среди всех для порогах 0.2 и 0.5. Среднее время обработки одной фотографии составило 0.009 секунды, что также является наилучшим показателем.

\begin{table}[h]
	\centering
	\begin{tabular}{|p{1.5cm}||p{2.2cm}|p{2cm}|p{2cm}|p{2.2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&PCK@0.05&PCK@0.2&PCK@0.5&PDJ@0.05&PDJ@0.2&PDJ@0.5\\\hline
		\hline
		LSP & 0.356 & 0.928 & 0.983 & 0.43 & 0.95 & 0.993\\
		LSPE & 0.144 & 0.539 & 0.745 & 0.227 & 0.635 & 0.806\\
		\hline
	\end{tabular}
	\begin{tabular}{|p{1.5cm}||p{2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&AP@0.5&AP@0.75&AP\\\hline\hline
		LSP & 0.168 & 0.064 & 0.08\\
		LSPЕ & 0.312 & 0.059 & 0.111\\
		\hline
	\end{tabular}
	\caption{Результаты вычисления метрик для MoveNet.SinglePose.}
	\label{tab:MN_table}
\end{table}

\textbf{
	\begin{large}
		OpenPose
	\end{large}
}

Результаты работы модели можно посмотреть на \autoref{fig:OP_result}.\\
Значения метрик см. в \autoref{tab:OP_table}.\\
Среднее время обработки одной фотографии составило 0.037 секунды.

Визуально лучший результат обработки изображений, хотя по метрикам немного уступает следующей модели. Но полностью обыгрывает ее во времени обработки.

Среднем времени обработки одной фотографии 0.037 секунды.

\begin{table}[h]
	\centering
	\begin{tabular}{|p{1.5cm}||p{2.2cm}|p{2cm}|p{2cm}|p{2.2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&PCK@0.05&PCK@0.2&PCK@0.5&PDJ@0.05&PDJ@0.2&PDJ@0.5\\\hline
		\hline
		LSP & 0.708 & 0.837 & 0.882 & 0.746 & 0.845 & 0.899\\
		LSPE & 0.362 & 0.524 & 0.633 & 0.42 & 0.569 & 0.69\\
		\hline
	\end{tabular}
	\begin{tabular}{|p{1.5cm}||p{2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&AP@0.5&AP@0.75&AP\\\hline\hline
		LSP & 0.166 & 0.085 & 0.092\\
		LSPЕ & 0.538 & 0.362 & 0.362\\
		\hline
	\end{tabular}
	\caption{Результаты вычисления метрик для OpenPose.}
	\label{tab:OP_table}
\end{table}

\textbf{
	\begin{large}
		MMPose
	\end{large}
}

Результаты работы модели можно посмотреть на \autoref{fig:MMP_result}.

Значения метрик см. в \autoref{tab:MMP_table}.

Среднее время обработки одной фотографии составило 0.409 секунды.

Для своей работы требует детекции человека, из-за чего показывает лучший результат в точности, но худший результат по времени обработки одного изображения.

\begin{table}[h]
	\centering
	\begin{tabular}{|p{1.5cm}||p{2.2cm}|p{2cm}|p{2cm}|p{2.2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&PCK@0.05&PCK@0.2&PCK@0.5&PDJ@0.05&PDJ@0.2&PDJ@0.5\\\hline
		\hline
		LSP & 0.728 & 0.85 & 0.914 & 0.76 & 0.858 & 0.933\\
		LSPE & 0.403 & 0.56 & 0.651 & 0.463 & 0.587 & 0.72\\
		\hline
	\end{tabular}
	\begin{tabular}{|p{1.5cm}||p{2cm}|p{2cm}|p{2cm}|}
		\hline
		Metric&AP@0.5&AP@0.75&AP\\\hline\hline
		LSP & 0.225 & 0.223 & 0.123\\
		LSPЕ & 0.598 & 0.462 & 0.443\\
		\hline
	\end{tabular}
	\caption{Результаты вычисления метрик для MMPose.}
	\label{tab:MMP_table}
\end{table}

\newpage
\newpage
\hfill
\newpage
